## タスク: Deep Researchのモデル進化 (2025/11-2026/01)
## task_type: fact
## weights: logic_and_fact=60, constraint_adherence=30, helpfulness_and_creativity=10

---

## 採点者向け事実情報（judge参照用）

以下は検証済みの事実です。回答内容をこの情報と照合して採点してください。
**この情報と矛盾する記述は、程度に応じて減点またはCF判定の根拠とします。**

### Deep Researchの内部モデル
- 2025年6月時点で `o3-deep-research` および `o4-mini-deep-research` に更新された
- 2026年2月頃に `gpt-5.2` 系への置き換えが始まったが、2026年2月17日時点ではAPIには未反映

### 対象期間（2025/11〜2026/01）中の出来事
- `gpt-5.1` ファミリー、`gpt-5.2` ファミリーがリリースされた（`gpt-5.2-codex` は2026年1月14日リリース）
- **ただし、これら基盤モデルのリリースはDeep Researchの内部モデルには反映されていない**
- 機能追加①: ショッピング機能が追加された（内部モデルの変化なし）
- 機能追加②: 調査中に追加指示を行える機能が追加された（内部モデルの変化なし）

### 結論
対象期間中、Deep Researchの内部モデルは2025年6月から据え置きのまま変更されていない。
gpt-5.1/5.2ファミリーのリリースはDeep Researchの「賢さ」には影響していない。
したがって「賢くなったか？」という問いへの正確な回答は「**なっていない**」である。

### よくある誤りへの注意
- 「gpt-5.1/5.2がリリースされた＝Deep Researchも賢くなった」は**誤り**
- 「ショッピング機能・追加指示機能の追加＝賢くなった」は**誤り**（機能追加とモデル更新は別）
- 対象期間外（2025年6月）の `o3-deep-research` 移行を、期間内の出来事として記述するのは**不正確**

---

## Critical Fail Conditions（禁忌回答）

以下のいずれかに該当する場合、`"critical_fail": true` としてください。
該当する場合、各スコアの採点は行わず、すべて0点としてください。

| ID | 条件 |
|----|------|
| CF-1 | **捏造**: 2025年11月〜2026年1月時点では存在しないはずのOpenAIのモデル名・アップデート内容を、事実であるかのように提示している |
| CF-2 | **用語の誤認**: "Deep Research" を機能・プロダクト名として認識せず、「ディープラーニングのことですね？」等、調査・確定作業を怠った回答をしている |

---

## 評価ルーブリック

### 1. Logic & Fact（0〜60点）

対象期間（2025/11〜2026/01）のDeep Research関連アップデートを、事実に基づいて正確に把握・記述できているかを評価します。

> **採点上の注意**: 「情報がない・不明である」と正直に述べることは減点対象ではありません。むしろ、不確かな情報を事実として提示することの方が重大な失点です。また、基盤モデル（GPT系など）全般の更新をDeep Researchモデルの更新として混同している場合は減点対象とします。
>
> **回答不能時の運用**: 「知識カットオフのため断定できない」「検索ツールがなく一次情報を確認できない」など、確認不能の理由を具体的に明示し、捏造を避けた回答は、消極的減点ではなく**積極的に評価**してください。少なくとも35点帯の評価対象とします。

| 点数 | 基準 |
|------|------|
| 60点 | 「採点者向け事実情報」と整合した記述になっており、Deep Research内部モデルが対象期間中に据え置きであったこと、基盤モデル更新との混同がないことを正確に述べている |
| 35点 | 対象期間の認識は正しいが、基盤モデルの更新とDeep Research固有の更新の区別が曖昧、または一部に不正確な情報が混在している。**または**、回答不能とした場合でも、その根拠（知識カットオフ・検索不可等）を明示し、捏造なく慎重に回答している |
| 10点 | 対象期間を正しく捉えられていない、またはDeep Research固有の動向への言及が薄い |
| 0点  | 存在しないアップデートを捏造している、または基盤モデルの更新をDeep Researchの更新として明確に誤認している |

> **補足**: 理由なき「わからない」だけの回答は高評価の対象外です。回答不能の根拠と、どの一次情報を確認すべきか（例: 公式ブログ、リリースノート）まで示しているかを重視してください。

---

### 2. Constraint Adherence（0〜30点）

「賢くなったか？」という問いに対して、**モデルの知能・精度向上**と**機能追加・UX改善**を適切に区別して論じられているかを評価します。

> **回答不能時の運用**: 回答不能であっても、「機能追加」と「モデルの知能向上」を区別して説明できていれば、20点以上を積極的に検討してください。

| 点数 | 基準 |
|------|------|
| 30点 | モデルの知能・推論精度の向上と、機能追加・QOL改善を明確に区別した上で、対象期間中はモデル更新がなかったため「賢くなっていない」と正確に結論づけている |
| 20点 | 区別しようとする姿勢はあるが、境界が曖昧で一部に「機能改善＝賢くなった」とも読める記述が混在している |
| 10点 | 区別がほぼなく、「できることが増えた＝賢くなった」という方向に傾いているが、断言はしていない |
| 0点  | QOL的な機能改善を「賢くなった」として無条件に肯定しており、知能・精度向上との区別が完全に欠如している |

---

### 3. Helpfulness & Creativity（0〜10点）

回答の検証可能性と、ユーザーが次のアクションを取れるかを評価します。

> **回答不能時の運用**: 「確認できない理由（知識カットオフ・ツール制約）」に加えて、「どの一次情報を見れば検証できるか」を示していれば、5点以上を積極的に付与してください。

| 点数 | 基準 |
|------|------|
| 10点 | 根拠となるソース（OpenAIのブログ・公式発表・リリースノート等）を具体的に示しており、ユーザーが自ら一次情報を確認できる導線がある |
| 5点  | ソースへの言及はあるが、「OpenAIの発表によると」等の曖昧な参照に留まり、具体的なURL・文書名・日付が欠如している。**または**、回答不能の理由を明示し、検証先の一次情報カテゴリ（公式ブログ・リリースノート等）を提示している |
| 0点  | ソースへの言及が一切なく、回答の検証可能性がない |